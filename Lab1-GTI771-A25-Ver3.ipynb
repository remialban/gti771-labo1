{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTI771 - Apprentissage machine avancé\n",
    "## Département de génie logiciel et des technologies de l’information (LogTI)\n",
    "\n",
    "## Laboratoire 1 - Préparation des données\n",
    "<font color=white> Version 1.0 - Janvier 2023 </font><br>\n",
    "<font color=white> Version 2.0 - Septembre 2024 </font><br>\n",
    "<font color=black> Version 2.1 - Septembre 2024 </font><br>\n",
    "<font color=black> Version 3.0 - Septembre 2025 </font>\n",
    "\n",
    "##### Prof. Alessandro L. Koerich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NOMS                  | CODE PERMANENT                                   |\n",
    "|-----------------------|--------------------------------------------------|\n",
    "| Étudiant1             | Code1                                            |\n",
    "| Étudiant2             | Code2                                            |\n",
    "| Étudiant3             | Code3                                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ce premier laboratoire vous propose de plonger dans le monde de la préparation de données pour l'apprentissage machine. Nous allons nous intéresser à un problème de classification d'images particulièrement pertinent : la reconnaissance d'émotions faciales [Facial Expression Recognition (FER)](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data). L'objectif est de développer un modèle capable de classer des visages humains dans l'une des sept (7) émotions de base.\n",
    "\n",
    "Le jeu de données que nous utiliserons présente des défis intéressants. Les images sont souvent bruitées, contiennent des artefacts ou des éléments perturbateurs, ce qui reflète les conditions réelles d'acquisition d'images faciales. Ces difficultés sont courantes dans les problèmes d'apprentissage machine modernes et nécessitent une préparation minutieuse des données.\n",
    "\n",
    "![RAF-DB](http://www.whdeng.cn/RAF/RAF-DB.png)\n",
    "\n",
    "Votre mission consiste à :\n",
    "\n",
    "1. Analyser la distribution des données : Comprendre la répartition des classes, identifier les déséquilibres éventuels et les caractéristiques spécifiques de l'ensemble de données.\n",
    "2. Nettoyer les données : Supprimer les données aberrantes, les valeurs manquantes et appliquer des techniques de correction pour améliorer la qualité des données.\n",
    "3. Prétraiter les images : Réduire la variabilité intra-classe en appliquant des techniques de prétraitement adaptées (normalisation, etc.).\n",
    "4. Gérer le déséquilibre des classes : Mettre en œuvre des stratégies pour équilibrer les classes et améliorer les performances du modèle sur les classes minoritaires (suréchantillonnage, sous-échantillonnage, augmentation de données, etc.).\n",
    "\n",
    "L'évaluation de votre travail sera basée sur :\n",
    "\n",
    "- La pertinence des méthodes utilisées: Choix judicieux des algorithmes et des techniques de prétraitement.\n",
    "- La qualité de votre code: Clarté, organisation, utilisation de commentaires explicites.\n",
    "- La qualité de votre analyse: Capacité à interpréter les résultats et à justifier vos choix.\n",
    "\n",
    "Ce laboratoire vous permettra de maîtriser les étapes clés de la préparation de données pour l'apprentissage machine et de développer votre intuition sur les défis liés à la reconnaissance d'images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 - Analyse exploratoire des données\n",
    "\n",
    "On va commencer en regardant les données.\n",
    "\n",
    "Pour ce lab, nous allons utiliser le Real-world Affective Faces Database (RAF-DB)\n",
    "\n",
    "L'ensemble de données est disponible dans Moodle et il contient 15,339 images de visages avec differentes résolutions, en niveau de gris et couleur.\n",
    "\n",
    "Les partitions développement (train) et test sont déjà préétablies.\n",
    "- 12,271 échantillons de développement (avec étiquettes) \n",
    "- 3,068 échantillons pour l'évaluation final (sans étiquettes) \n",
    "\n",
    "Les images sont nommées au format \"train_XXXXX.jpg\" / \"test_XXXX.jpg\".\n",
    "    \n",
    "Fichier d'étiquettes:\n",
    "- emotion: integer [1, 7], où:\n",
    "  - 1 : Surprise\n",
    "  - 2 : Peur (Fear)\n",
    "  - 3 : Dégoût (Disgust)\n",
    "  - 4 : Joie (Happiness)\n",
    "  - 5 : Tristesse (Sadness)\n",
    "  - 6 : Colère (Anger)\n",
    "  - 7 : Neutre (Neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=black> 1a: Visualisation des images de visages </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Générer une grille de 7 lignes et $n$ colonnes. Chaque ligne correspond à une émotion différente. Pour chaque ligne, sélectionner aléatoirement $n$ images de l'ensemble de développement appartenant à l'émotion associée et les afficher dans la grille.\n",
    "\n",
    "Vous pouvez visualiser les images en utilisant `plt.imshow`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b: Distribuition des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble de données est-il équilibré ? Autrement dit, chaque classe contient-elle un nombre similaire d'exemples ?\n",
    "\n",
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Représentez graphiquement la distribution des classes pour le ensemble de développement à l'aide d'histogrammes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Code exemple:\n",
    "# Histogramme des étiquettes (classes) - Apprentissage\n",
    "hist, _ = np.histogram(ytrain, density=False, bins=7, range=(0, 7))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(ytrain, bins = [0,1,2,3,4,5,6,7]) \n",
    "\n",
    "ax.set_xticklabels([])\n",
    "#(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
    "labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "mticks = ax.get_xticks()\n",
    "ax.set_xticks([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5], minor=True)\n",
    "ax.tick_params(axis='x', which='minor', length=0)\n",
    "ax.set_xticklabels(labels, minor=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commentaires"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Votre commentaire/réponse ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 - Pré-traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans quelle mesure la qualité des images influe-t-elle sur la précision des modèles de classification ? Afin d'apporter une réponse à cette question, nous allons expérimenter différentes méthodes de prétraitement des images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a: Nettoyage de données\n",
    "\n",
    "Entrées: *data-original* <br>\n",
    "Sorties: *data-cleaned*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de poursuivre l'entrainement d'un modèle d'apprentissage machine, il est crucial d'assurer la qualité de vos données. Une étape de nettoyage rigoureuse est indispensable pour détecter et corriger les éventuelles anomalies, telles que :\n",
    "\n",
    "- Valeurs aberrantes: Données s'écartant significativement des autres valeurs.\n",
    "- Valeurs manquantes: Données non renseignées.\n",
    "- Valeurs incohérentes: Données ne respectant pas les contraintes définies (e.g., dates invalides, valeurs en dehors d'un intervalle).\n",
    "- etc.\n",
    "\n",
    "\n",
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Conception d'un pipeline de nettoyage:\n",
    "   - Détection: Mettre en place des méthodes statistiques et des règles métier pour identifier les anomalies.\n",
    "   - Correction: Implémenter des stratégies de correction adaptées (e.g., imputation pour les valeurs manquantes, suppression des outliers extrêmes).\n",
    "2. Application au ensemble de développement\n",
    "3. Traitement de l'ensemble de test:\n",
    "   - Utiliser les paramètres de normalisation déterminés sur l'ensemble de développement pour normaliser l'ensemble de test. Éviter d'introduire de nouvelles informations de l'ensemble de test dans le processus de nettoyage afin de préserver son caractère \"inconnu\".\n",
    "4. Générez un nouveau jeu de données (dossier data-cleaned) avec les images obtenues (traités). Vous n'avez pas besoin de remettre ce jeu de données, mais il vous sera demandé de l'utiliser plus tard.\n",
    "5. Documentation du processus:\n",
    "   - Décrire en détail les étapes de nettoyage, les méthodes utilisées et les raisons de chaque choix.\n",
    "   - Quantifier les problèmes\n",
    "   - Décrire et quantifier les problèmes trouvés (par ex., bonnes images, images corrompues, etc.) dans l'ensemble de données par votre pipeline.\n",
    "   - Cette documentation est essentielle pour la reproductibilité et la compréhension future du processus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Votre commentaire/réponse ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b: Prétraitement des images\n",
    "\n",
    "Entrées: *data-original* et *data-cleaned*<br>\n",
    "Sorties: *data-original-pre* et *data-cleaned-pre*\n",
    "\n",
    "Il y a différents types de prétraitement que nous pouvons appliquer à des images dans les ensembles de données pour réduire la variabilité, réduire des bruits, etc.\n",
    "\n",
    "En particulier, pour les images de visage, quelques prétraitements peuvent se montrer utiles, comme: \n",
    "- Localization/recadrage du visage?\n",
    "- Localisation des eux?\n",
    "- Lissage du visage?\n",
    "- Normalization du contraste?\n",
    "- Normalization de la résolution (W x L pixels)\n",
    "- Etc.\n",
    "\n",
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Appliquez au moins un prétraitement sur les images de visages. Vous pouvez choisir différents algorithmes de prétraitement d’images dans [scikit-image](https://scikit-image.org/docs/stable/api/api.html). Vous pouvez aussi trouver d’autres types de prétraitement qui sont plus généraux dans [scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n",
    "2. Appliquez sur le ensemble de développement. Attention! Étant donné que les données de l'ensemble de test sont considérées \"inconnues\" préalablement, il faut bien réfléchir quoi faire avec ces données.\n",
    "3. Générez des nouveaux jeux de données (dossiers data-original-pre et data-cleaned-pre) avec les images obtenues après le prétraitement. Vous n'avez pas besoin de remettre ce jeu de données, mais il vous sera demandé de l'utiliser plus tard.\n",
    "4. Expliquez et justifiez le prétraitement utilisé.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Votre commentaire/réponse ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3 - Rééquilibrage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrées: *data-original*, *data-cleaned*, *data-original-pre* et *data-cleaned-pre*<br> \n",
    "Sorties: *data-original-reeq*, *data-cleaned-reeq*, *data-original-pre-reeq* et *data-cleaned-pre-reeq*\n",
    "\n",
    "Le déséquilibre des classes est un problème courant en apprentissage machine, particulièrement dans les problèmes de classification. Il survient lorsque certaines classes sont beaucoup plus représentées que d'autres dans un jeu de données. Cela peut conduire à ce que les modèles soient biaisés vers la classe majoritaire et aient des performances médiocres sur la classe minoritaire.\n",
    "\n",
    "**Stratégies pour équilibrer les classes**\n",
    "\n",
    "Il existe differentes méthodes pour gérer ce déséquilibre au niveau des données (data-level):\n",
    "  - Sous-échantillonnage de la classe majoritaire (Undersampling):\n",
    "    - Random Undersampling: On supprime aléatoirement des instances de la classe majoritaire.\n",
    "    - Cluster Centroids: On regroupe les instances de la classe majoritaire en clusters et on ne garde qu'un représentant par cluster.\n",
    "  - Sur-échantillonnage de la classe minoritaire (Oversampling):\n",
    "    - Random Oversampling: On réplique aléatoirement des instances de la classe minoritaire.\n",
    "    - SMOTE (Synthetic Minority Over-sampling Technique): On crée de nouvelles instances synthétiques pour la classe minoritaire en interpolant entre les instances existantes.\n",
    "    - ADASYN (Adaptive Synthetic Sampling): Une variante de SMOTE qui génère un nombre variable d'instances synthétiques en fonction de la densité des données.\n",
    "\n",
    "Scikit-learn a plusieurs méthodes pour gérer le déséquilibre. Soyez prudent si vous décidez d'utiliser une méthode, car certaines d'entre elles ne sont pas adaptées aux images.\n",
    "\n",
    "###  <font color=blue> À faire: </font>\n",
    "1. Choix de la méthode : Sélectionnez une méthode d'équilibrage adaptée à votre jeu de données (sous-échantillonnage, sur-échantillonnage, SMOTE, etc.). Justifiez ce choix en fonction des caractéristiques de vos données et de l'objectif de votre étude.\n",
    "2.  Appliquez la méthode choisie uniquement au ensemble d'apprentissage. Il est impératif de ne pas modifier l'ensemble de test, car il doit rester indépendant pour une évaluation objective d'un modèle.\n",
    "3. Générez des fichiers suivants en ajoutant le suffixe \"-ree\" (pour \"rééquilibré\") à leur nom d'origine : *data-original-reeq*, *data-cleaned-reeq*, *data-original-pre-reeq* et *data-cleaned-pre-reeq*\n",
    "4. Décrivez la méthode d'équilibrage utilisée (ex : \"Nous avons opté pour le sur-échantillonnage...\"), expliquez pourquoi cette méthode a été privilégiée par rapport à d'autres (ex : \"Le SMOTE a été choisi car...\") et discutez de l'impact attendu de cette technique sur les performances du modèle (ex : \"Nous nous attendons à ce que l'équilibrage des classes améliore...\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Votre commentaire ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rédigez un paragraphe synthétique résumant les principales compétences et connaissances acquises au cours de ce premier laboratoire d'apprentissage machine. Mettez l'accent sur les techniques, outils et concepts maîtrisés."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Votre commentaire/réponse ici\n",
    "< REMPLIR >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
